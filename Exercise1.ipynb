{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Credit Risk Analysis</center></h1>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, normalize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from scipy.stats import chi2_contingency,ttest_ind\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "\n",
    "Let's take a quick look at the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cust_pd_full = pd.read_csv('./data/CUST_HISTORY_1000.csv')\n",
    "\n",
    "# rows=1000\n",
    "cust_pd = cust_pd_full # .head(rows)\n",
    "print(\"There are \" + str(len(cust_pd_full)) + \" observations in the customer history dataset.\")\n",
    "print(\"There are \" + str(len(cust_pd_full.columns)) + \" variables in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataframe into Features and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_pd_Y = cust_pd[['IS_DEFAULT']]\n",
    "cust_pd_X = cust_pd.drop(['IS_DEFAULT'],axis=1)\n",
    "\n",
    "print('cust_pd_X.shape=%s, cust_pd_Y.shape=%s'% (cust_pd_X.shape, cust_pd_Y.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_pd_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "cust_pd_Y['IS_DEFAULT'] = le.fit_transform(cust_pd_Y['IS_DEFAULT'])\n",
    "cust_pd_Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'features df shape = {cust_pd_X.shape}')\n",
    "cust_pd_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder for categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = ['CREDIT_HISTORY', 'TRANSACTION_CATEGORY', 'ACCOUNT_TYPE', 'ACCOUNT_AGE',\n",
    "                      'STATE', 'IS_URBAN', 'IS_STATE_BORDER', 'HAS_CO_APPLICANT', 'HAS_GUARANTOR',\n",
    "                      'OWN_REAL_ESTATE', 'OTHER_INSTALMENT_PLAN',\n",
    "                      'OWN_RESIDENCE', 'RFM_SCORE', 'OWN_CAR', 'SHIP_INTERNATIONAL']\n",
    "cat_indexes =  [cust_pd_X.columns.get_loc(col) for col in categoricalColumns]\n",
    "cat_indexes = np.asarray(cat_indexes)   # .ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelList=[]\n",
    "labelEncoderList={}\n",
    "for col in categoricalColumns:\n",
    "    labenc = LabelEncoder()\n",
    "    cust_pd_X[col] = labenc.fit_transform(cust_pd_X[col]) \n",
    "    labelEncoderList[col] = labenc\n",
    "    newclas = [col + \"_\" + str(clas).replace(' ', '_') for clas in labenc.classes_ ]\n",
    "    labelList.append(np.asarray(newclas))\n",
    "labelEncoded_X = cust_pd_X\n",
    "cust_pd_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collabelList = np.concatenate( labelList, axis=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding for categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_enc = OneHotEncoder(categorical_features=cat_indexes, handle_unknown='ignore', n_values=\"auto\")\n",
    "OH_enc.fit(cust_pd_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcols = np.append(collabelList, [\"EMI_TENURE\", \"TRANSACTION_AMOUNT\", \"NUMBER_CREDITS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_pd_X_enc = OH_enc.transform(cust_pd_X)\n",
    "cust_pd_X_df = pd.DataFrame(cust_pd_X_enc.toarray(), columns=newcols)\n",
    "cust_pd_X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(cust_pd_X_df)\n",
    "features = min_max_scaler.transform(cust_pd_X_df)\n",
    "features = normalize(features, axis=1, norm='l1')\n",
    "\n",
    "cust_pd_X = pd.DataFrame(features,columns=newcols)\n",
    "cust_pd_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label    = cust_pd_Y.values\n",
    "features  = cust_pd_X.values\n",
    "\n",
    "label = np.reshape(label,(-1,1))\n",
    "# label = np.float32(label)\n",
    "X_train,X_test,y_train,y_test = \\\n",
    "       train_test_split(features, label, test_size=0.3, random_state=42, stratify=label)\n",
    "print(f'X_train.shape={X_train.shape} Y_train.shape={y_train.shape}')\n",
    "print(f'X_test.shape={X_test.shape} Y_test.shape={y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sklearn_lr = LogisticRegression(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "t0 = time.time()\n",
    "sklearn_lr.fit(X_train, y_train)\n",
    "print(\"[sklearn] Training time (s):  {0:.5f}\".format(time.time()-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate log-loss on test set\n",
    "# proba_test = sklearn_lr.predict_proba(X_test)\n",
    "# from sklearn.metrics import log_loss\n",
    "# logloss_sklearn = log_loss(y_test, proba_test)\n",
    "# print(\"[sklearn] Logarithmic loss:   {0:.4f}\".format(logloss_sklearn))\n",
    "sklearn_prediction = sklearn_lr.predict(X_test)\n",
    "print(f'sklearn ml accuracy score = {accuracy_score(y_test,sklearn_prediction)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how good is our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_order = labelEncoded_X.columns.tolist()\n",
    "labelEncoded_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data without Onehot Encoder as RandomForest works best with Categorical columns\n",
    "min_max_scaler_ = MinMaxScaler()\n",
    "cust_pd_X_ = min_max_scaler_.fit_transform(labelEncoded_X)\n",
    "cust_pd_X_ = normalize(cust_pd_X_, axis=1, norm='l1')\n",
    "cust_pd_X_ = pd.DataFrame(cust_pd_X_,columns=features_order)\n",
    "\n",
    "features_  = cust_pd_X_.values\n",
    "label_    = cust_pd_Y.values\n",
    "\n",
    "label_ = np.reshape(label_,(-1,))\n",
    "\n",
    "X_train_,X_test_,y_train_,y_test_ = \\\n",
    "       train_test_split(features_, label_, test_size=0.3, random_state=42, stratify=label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "#Stratify split and train on 5 folds\n",
    "skf = StratifiedKFold(y_train_, n_folds=5)\n",
    "counter = 1\n",
    "for train_fold, test_fold in skf:\n",
    "    random_forest.fit(X_train_[train_fold], y_train_[train_fold])\n",
    "    print( str(counter) + \": \", random_forest.score(X_train_[test_fold], y_train_[test_fold]))\n",
    "    counter += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Top feature which influence the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X_train_, y_train_)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(5):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, features_order[indices[f]], importances[indices[f]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
